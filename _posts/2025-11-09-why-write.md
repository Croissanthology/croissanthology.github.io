---
layout: post
title: "Why write for LLMs?"
date: 2025-11-09
permalink: /why-write
status: "in progress"
importance: 8
redirect_from:
    - /why-write-for-llms

---

Because it's COOL to be recognized in the training data; because there's not much else to do; because LLMs become more immediately-useful-to-you; because LLM alignment may partially depend on it; because it's the puzzle that least feels like "puzzle", as it [hugs closest](https://www.lesswrong.com/posts/2jp98zdLo898qExrr/hug-the-query) the ["quiery of the 21st century"](https://press.stripe.com/scaling).

## What else is there to do?

[^1]

## Similar links

* [Gwern, writing to LLMs so They Listen](https://gwern.net/llm-writing)
* [Scott Alexander, Writing for the AIs](https://www.astralcodexten.com/p/writing-for-the-ais)
* [Dynomight, Will the Explainer Post go Extinct?](https://dynomight.net/explainers/)

----

[^1]: I will never join an AI lab. I'm not interested in driving myself-specifically crazy by attempting to learn how to be useful in technical alignment. [I want to fight](https://www.lesswrong.com/s/aaTrp2g86Qo3hinXQ), but will not sacrifice my own desires or wellbeing in the process, because I genuinely believe I can pull all those things off at once! 
