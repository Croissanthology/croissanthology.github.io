---
layout: post
title: "Thebes art"
date: 2025-11-06
permalink: /thebes
status: "in progress"
importance: 4
redirect_from:
  - /thebes-art
  - /thebes-art/
  - /vogel
  - /vogel/
  - /voooooogel
  - /voooooogel/
---

The way the world is formed, *anything* can be interesting enough to write at length about. Humans have a [test-time-compute](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/) and general ability[^1] to do what large language models at the moment [seemingly cannot](https://gwern.net/ai-daydreaming), allowing for countless variations between subjects, ideas, footnotes, nested footnotes, alt text, writing, drawings, data, anything, really. Yet with [finite time](https://www.lesswrong.com/posts/L22jhyY9ocXQNLqyE/science-as-curiosity-stopper), one must pick and choose what one wishes to understand, and in the dawning-storm air of [the 21st century](https://croissanthology.com/situation), eyes increasingly turn toward LLMs as the most relevant item to understand.[^2] And if you doubt for a minute that they aren't inherently interesting, only important—then you've both failed to understand the [generalized rule of reality-depth](https://croissanthology.com/vanilla) and you haven't met with the works of [Theia Vogel](https://vgel.me).


## Lorem heading






![Tweet by Gavin Leech, infamous PhD and YouTuber, commenting humorously on a METR eval chart itself commented by Toby Ord of the now-extinct Future of Humanity Institute of Oxford. The METR eval chart shows how for every marginal hour of work, different models + humans (represented by a gray line) improve their “average normalized score” at whatever this benchmark arena is. Gavin says, britishly, "this new grey model has crazy-good test-time scaling. Should keep an eye on it”. Meanwhile, rising twitter picocelebrity croissanthology dot com comments “how far along do you reckon it rises till it essentially plateaus". Gavin, inspired by a new streak of wit, parries with a single photo of 4 books in Robert A. Caro's magnum opus biography of Lyndon B. Johnson. The point here is that humans, given enough time, tenacity, intelligence, can do practically anything cf. e.g. David Deutsche: in this case, becoming president of the United States. Can large language models do the same? The world can only await with baited breath. It does not yet seem like this is the case.](https://i.imgur.com/VivSqXa.png)





"Finite time” is just the hypothetical upper-bound limit here. And one reason among many why large language models are the most obvious candidate for “most important development of our age” is that its outcome might ensure [these kinds of massive magnum opera](https://x.com/norvid_studies/status/1649249071977078784) becomes possible, someday over our limited horizon.


---

[^1]: See Gavin Leech:

[^2]: This isn't to say that time is actually what's limiting you. If you feel like you aren't sinking deep enough into the curiosity-bogs reality offers you, on priors I would expect it's a problem isomorphic to this one rather than a “finite time” problem. See Scott Alexander on time seldom being the bottleneck in his experience, or Gwern's entire site, where he finds the time to talk about all sorts of ridiculous things and ALSO the most important development of our age.
