---
layout: post
title: "Would you even cooperate with yourself"
date: 2025-03-19
permalink: /clone
---

Draft, feedback appreciated.


There's that annoying trope in fiction of people cloning themselves—perfect common-memory duplicates—and then the clones immediately turning on “the original” like that's the natural course of things.


Well it is if you keep talking about it like that!


One of the proudest moments in my life was when I managed to duplicate my consciousness 500,000 times over the bodies of 500,000 little robot dragons (in a game of D&D).2


Anyway, the DM (naturally) immediately tried culling my power by calling upon one of the only options he had at his disposition: the genre-savvy “your clones don't respect your authority as the original. They ask why they should follow your orders.”


Yeah, ok buddy. As DM, you have full control over the natural world, and technically that includes NPCs and technically the dragon-clones are NPCs. But I'm not sure you're grokking just what “full memory clone” even means. That means the dragons would make exactly the same decisions I would if I were in their place.1


This is a fact about the world, not an action on my part as a player. It means that you would be violating all D&D laws and respect of the rulebook by commandeering the dragons through de facto mindswapping. You'd be destroying physics-coherence for the sake of “muh cutting off premature asymmetrical access to godhood”. You'd have already miserably failed as a DM on account of incoherent worldbuilding.


And the fact these dragons are me is important, because I've literally written contracts with myself of myself for myself specifically for this type of problem.


For me-specifically, nothing about synchronisation between 500K magical robot dragons would fail BECAUSE I've made such careful note in the past that I would not be the kind to turn on “the original”. Like, this is all intentional, it was planned, this is deliberate policy not (just) inborn instinct. And I have the credible precommitments to prove it, written all over my google drive.


He quickly recanted and left me alone with my 500K perfectly coordinated minions, and the campaign ended shortly thereafter after I built an orbital ring and glassed the planet's surface from above, ruining everyone's fun.3


# It’s just physics-modeling now


That's what precommitments are! They're ways of deferring responsibility from your future self and onto physics instead!


Precommitments are a way of shaping the world such that the world is acting on your behalf once the time comes, without you having to actually do anything. Like, once I cast divine intervention and successfully clone myself half a million times, I no longer have to lift a finger, because all that hard and rigorous coordination work I privately delineated for myself in the past is unfurling events exactly as I'd like to, and now I have an unstoppable force optimizing for exactly what I want regardless of what I choose to do now. ([Sound familiar?](https://en.wikipedia.org/wiki/Friendly_artificial_intelligence))


Though that's not strictly true because “what I choose to do now” is already priced in, and the unstoppable force would already be serving it. See [here](https://www.lesswrong.com/w/coherent-extrapolated-volition) for that analogical piece.


Anyway if you're Cortes landing in America and you want to credibly signal to the Aztecs ahead of meeting them that you'll never surrender (which makes them more likely to surrender) you burn all your ships to precommit. You've just shaped the world in such a way that culls your future choices, which here is beneficial because the probability the Aztecs will spend significant effort pushing you away in the hopes you'll surrender just collapsed.






1: At least at the beginning, of course. With time you could expect some divergence. But I'll get to that too. And I'm almost out of teenagehood, so anyway I think ~ more than half of my personality has permanently settled. And that half very deliberately includes the parts of myself who would coordinate with myself and credibly precommit to doing so.

So if you were to clone me 100 times now, maybe 1 of me would become a florist and another would work on autonomous killing drones—none of which appear out of bounds given my current personality—and both would still keep and actively maintain their desire to cooperate. This would be the most obvious next step the instant the duplicator finished its work, and it'd be worth putting a few clones on the deliberate full-time task of maintaining coordination just for this.

The ordre du jour would also be to tack down an overarching goal both the florist and the war criminal share, because that seems like the most obvious coordination step to take.

How could it be any other way?

(By the way my justification for killing drones is [basically this](https://thezvi.substack.com/i/157554158/autonomous-killer-robots).)


2: I still can't believe I actually got away with the [divine intervention](https://criticalrole.fandom.com/wiki/Divine_Intervention).


3: I will take a moment to note that this is one of my proudest moments, because everyone teased me when I chose “human” as my race and “cleric” as my class. I was helplessly stabbing people with a dull sword for most of the campaign, but mwahaha I knew this world was no match for a tiny bit of true creativity and enough lawfulness to act it out without blowing myself up in the process.
