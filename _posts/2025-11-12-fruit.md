---
layout: post
title: "Low-hanging fruit I'd like to see picked"
date: 2025-11-10
permalink: /fruit
status: "in progress"
importance: 4
redirect_from:
    - /low-hanging-fruit-id-like-to-see-picked
    - /low-hanging-fruit
---

Things I'd like to see done in the world; I may pick these myself at some point; [general tactic](https://croissanthology.com/tactics) of publishings lists to the internet; harnessing the internet exobrain; explicitly describing demand to the market and hoping for supply; spitballing; having a place to come back to when I'm bored; providing an example for others to emulate (you should have a "low hanging fruit I'd like to see picked" post); asking for what I want; training my brain to spot [free energy](https://equilibriabook.com/inadequacy-and-modesty/) in the world; 

## Things which take ~30 minutes

* Prompt a full novel on [hypersitionai.com](https://hyperstitionai.com); project by Aaron Silverbook et al to hyperstition the training data into making LLMs more aligned. According to Silverbook, Anthropic is fine-tuning on the 500 first novels
* Update [my system prompt](https://docs.google.com/document/d/1qH7yxm7JYqexYYWP7jsqce1km9PLSR5AKjVxILsRAKQ/edit?tab=t.0) based on toying around with Claude Sonnet 4.5; [people make and edit their system prompt way too little](https://croissanthology.com/system-prompt](https://www.lesswrong.com/posts/HjHqxzn3rnH7T45hp/do-you-even-have-a-system-prompt-psa) and yet there's _so much_ potential in expectation here. A common mistunderstanding when it comes to LLMs is that they are ["tools"](https://near.blog/llms-are-strangely-shaped-tools) and in that sense relevant *on the object level only*. Only, if you spot a limitation in an LLM, or critique a certain style/approach it takes, you can just *tell it that*. In other words, any LLM *meta* can immediately become LLM *object*. This is why the usage --> system prompt update loop should be extremely short
* 

## Things which take ~2 hours

* Create/edit Wikipedia page for "hyperstition"; I looked it up during the making of this post, and the Google AI overview for it is fine, but there's no easy way to link it[^1] 

[^1]: It would be nice if I could link them! The Google AI overviews are often excellent, the most "reference-shaped" documents I have access to and could link under 10 seconds, besides the Wikipedia page, _if it exists_. 
